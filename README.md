# AI-Driven Book + RAG Chatbot

An intelligent book generation and RAG-powered chatbot system for the hackathon project.

## Project Structure

```
book/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py         # FastAPI endpoints
â”‚   â”‚   â”œâ”€â”€ embed.py        # Embedding generation
â”‚   â”‚   â”œâ”€â”€ rag.py          # RAG engine
â”‚   â”‚   â”œâ”€â”€ qdrant_client.py # Vector database
â”‚   â”‚   â””â”€â”€ schema.py       # Data models
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ frontend/               # Docusaurus book
â”‚   â””â”€â”€ my-book/
â”‚       â”œâ”€â”€ docs/           # Book content
â”‚       â”œâ”€â”€ static/chatbot/ # Chat UI
â”‚       â””â”€â”€ src/theme/      # Text selection
â”œâ”€â”€ .env                    # Configuration
â””â”€â”€ README.md
```

## Setup Instructions

### Prerequisites

- Python 3.10+
- Node.js 18+
- Qdrant (running locally or cloud)
- API Keys:
  - Anthropic API key (required)
  - OpenAI API key (for embeddings)
  - Google API key (optional fallback)

### Backend Setup

1. **Install Qdrant**:
   ```bash
   docker run -p 6333:6333 qdrant/qdrant
   ```

2. **Configure Environment**:
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

3. **Install Dependencies**:
   ```bash
   cd backend
   pip install -r requirements.txt
   ```

4. **Run Backend**:
   ```bash
   cd backend/src
   python main.py
   ```

   Backend will be available at `http://localhost:8000`

### Frontend Setup

1. **Install Dependencies**:
   ```bash
   cd frontend/my-book
   npm install
   ```

2. **Configure Backend URL**:
   Create `frontend/my-book/.env.local`:
   ```
   REACT_APP_BACKEND_URL=http://localhost:8000
   ```

3. **Run Development Server**:
   ```bash
   npm start
   ```

   Frontend will be available at `http://localhost:3000`

## Usage

### Embedding Book Content

Send POST request to `/embed-book` with book chapters:

```bash
curl -X POST http://localhost:8000/embed-book \
  -H "Content-Type: application/json" \
  -d '{
    "introduction": "Content here...",
    "chapter1": "Content here..."
  }'
```

### Querying the Chatbot

#### Global QA Mode
```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is ROS 2?",
    "mode": "global"
  }'
```

#### Selected Text QA Mode
```bash
curl -X POST http://localhost:8000/select \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Explain this concept",
    "mode": "selected",
    "context": "Selected text from the book..."
  }'
```

## Deployment

### ðŸš€ Quick Deploy (Recommended)

**Frontend â†’ Vercel | Backend â†’ Railway**

See [QUICK_DEPLOY.md](./QUICK_DEPLOY.md) for 10-minute deployment guide.

### Deployment Options

#### Option 1: Vercel + Railway (Recommended)
- **Frontend (Docusaurus)** â†’ Deploy to Vercel for global CDN
- **Backend (FastAPI)** â†’ Deploy to Railway for persistent connections
- **Best for**: Production apps with RAG chatbot

ðŸ“– **Full Guide**: [VERCEL_DEPLOYMENT_GUIDE.md](./VERCEL_DEPLOYMENT_GUIDE.md)

#### Option 2: GitHub Pages (Static Only)
- **Frontend only** â†’ Deploy static Docusaurus site
- **No backend features**: Chatbot, authentication, personalization won't work
- **Best for**: Documentation-only projects

```bash
cd frontend/my-book
npm run build
GIT_USER=<your-username> npm run deploy
```

#### Platform Comparison
See [DEPLOYMENT_PLATFORMS_COMPARISON.md](./DEPLOYMENT_PLATFORMS_COMPARISON.md) for detailed feature comparison.

### Environment Variables

Copy `.env.example` to `.env` and configure:
```bash
cp .env.example .env
# Add your API keys and configuration
```

Required:
- `GOOGLE_API_KEY` - Google Gemini API
- `ANTHROPIC_API_KEY` - Claude API
- `QDRANT_URL` and `QDRANT_API_KEY` - Qdrant Cloud
- `NEON_DB_URL` - Neon Postgres
- `BETTERAUTH_SECRET` - Random 32+ char string

## API Endpoints

### Health Check
- **GET** `/health` - Server status

### Embedding
- **POST** `/embed` - Embed single chapter
- **POST** `/embed-book` - Embed entire book

### RAG Queries
- **POST** `/query` - Global book QA
- **POST** `/select` - Selected text QA

## Features

### Core Features
- âœ… AI-generated book content (Docusaurus)
- âœ… RAG-powered chatbot with Gemini
- âœ… Global and selected-text QA modes
- âœ… Vector search with Qdrant Cloud
- âœ… Dark mode support

### Advanced Features
- âœ… User authentication (BetterAuth + Neon)
- âœ… Content personalization (based on user background)
- âœ… Translation to Urdu (RTL support)
- âœ… Multilingual i18n support

### Deployment
- âœ… Vercel deployment (frontend)
- âœ… Railway deployment (backend)
- âœ… GitHub Pages option (static only)

## Tech Stack

- **Backend**: FastAPI, Qdrant Cloud, Google Gemini
- **Frontend**: Docusaurus, React 19, TypeScript
- **AI**: Google Gemini for RAG, Anthropic Claude for personalization
- **Database**: Neon Serverless Postgres
- **Authentication**: BetterAuth
- **Deployment**: Vercel (frontend), Railway (backend)

## Development

### Running Tests
```bash
cd backend
pytest tests/
```

### Linting
```bash
cd frontend/my-book
npm run lint
```

### Building for Production
```bash
cd frontend/my-book
npm run build
```

## License

MIT

## Credits

Built for the AI Hackathon using Claude Code and Spec-Driven Development.
